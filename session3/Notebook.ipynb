{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation Based Inference\n",
    "\n",
    "#### Exercises Session 3\n",
    "\n",
    "##### Lorenzo Consoli\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 1\n",
    "\n",
    "Implement rejection sampling to obtain 10000 samples from the posterior distribution for the genetic linkage problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as  np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from scipy.optimize import minimize_scalar\n",
    "from tqdm import tqdm\n",
    "\n",
    "#proposal distribution\n",
    "def sample_uniform() -> float:\n",
    "    return np.random.uniform()\n",
    "\n",
    "def compute_log_likelihood(\n",
    "        theta: float,\n",
    "        class_counts: list[int] = [125, 18, 20, 34] \n",
    "    ) -> float:\n",
    "    y1, y2, y3, y4 = class_counts\n",
    "    likelihood = y1 * np.log(2 + theta) + \\\n",
    "        (y2 + y3) * np.log(1 - theta) + \\\n",
    "            y4 * np.log(theta)\n",
    "    return - likelihood\n",
    "\n",
    "def maximize_likelihood() -> float:\n",
    "    minimized_likelihood = minimize_scalar(compute_log_likelihood, bounds = [0, 1], method = \"bounded\")\n",
    "    return - minimized_likelihood.fun\n",
    "\n",
    "def accept_proposal(\n",
    "        theta: float,\n",
    "        unif_sample: float,\n",
    "        log_C: float\n",
    "    ) -> bool:\n",
    "    likelihood = - compute_log_likelihood(theta)\n",
    "    log_U = np.log(unif_sample)\n",
    "    #print(f\"theta {theta} log_U {log_U} likelihood {likelihood} log_C {log_C}\")\n",
    "    return log_U <= likelihood - log_C\n",
    "\n",
    "def rejection_sampling() -> float:\n",
    "    theta = sample_uniform()\n",
    "    unif_sample = sample_uniform()\n",
    "    log_C = maximize_likelihood()\n",
    "    while not accept_proposal(theta, unif_sample, log_C):\n",
    "        theta = sample_uniform()\n",
    "    return theta\n",
    "\n",
    "def genetic_linkage_rejection_sampling(\n",
    "        n_samples: int = 10000\n",
    "    ) -> list[float]:\n",
    "    samples = []\n",
    "    for sample in tqdm(range(n_samples)): \n",
    "        theta = rejection_sampling()\n",
    "        samples.append(theta)\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = genetic_linkage_rejection_sampling()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a histogram based on these samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(theta, bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approximate the posterior mean and standard deviation using\n",
    "these samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"posterior mean {np.mean(theta)} posterior std {np.std(theta)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(genetic_linkage_rejection_sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import t, norm\n",
    "import numpy as np\n",
    "\n",
    "# Define the function to evaluate f(x) = |x|\n",
    "def f(x):\n",
    "    return np.abs(x)\n",
    "\n",
    "# Define the unnormalized density in the logarithmic scale\n",
    "def log_p_bar(x):\n",
    "    return -2 * np.log(1 + x**2/3)\n",
    "\n",
    "# Define the logarithm of the probability density function for proposal distribution 1 (t-distribution with 3 degrees of freedom)\n",
    "def log_q1(x):\n",
    "    return t(df=3).logpdf(x)\n",
    "\n",
    "# Define the logarithm of the probability density function for proposal distribution 2 (t-distribution with 1 degree of freedom)\n",
    "def log_q2(x):\n",
    "    return t(df=1).logpdf(x)\n",
    "\n",
    "# Define the logarithm of the probability density function for proposal distribution 3 (standard Normal distribution)\n",
    "def log_q3(x):\n",
    "    return norm(loc=0, scale=1).logpdf(x)\n",
    "\n",
    "# Define the logarithm of the importance weight function for proposal distribution 1\n",
    "def log_w1(x):\n",
    "    return log_p_bar(x) - log_q1(x)\n",
    "\n",
    "# Define the logarithm of the importance weight function for proposal distribution 2\n",
    "def log_w2(x):\n",
    "    return log_p_bar(x) - log_q2(x)\n",
    "\n",
    "# Define the logarithm of the importance weight function for proposal distribution 3\n",
    "def log_w3(x):\n",
    "    return log_p_bar(x) - log_q3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define x values to evaluate the density functions\n",
    "x = np.linspace(-5, 5, 1000)\n",
    "\n",
    "# Evaluate the density functions for each proposal distribution\n",
    "p1 = t(df=3).pdf(x)\n",
    "p2 = t(df=1).pdf(x)\n",
    "p3 = norm(loc=0, scale=1).pdf(x)\n",
    "\n",
    "# Evaluate the weight functions for each proposal distribution\n",
    "w1 = np.exp(log_w1(x))\n",
    "w2 = np.exp(log_w2(x))\n",
    "w3 = np.exp(log_w3(x))\n",
    "\n",
    "# Plot the probability density functions of all three proposal distributions\n",
    "plt.plot(x, p1, label='t-distribution with 3 degrees of freedom')\n",
    "plt.plot(x, p2, label='t-distribution with 1 degree of freedom')\n",
    "plt.plot(x, p3, label='standard Normal distribution')\n",
    "plt.legend()\n",
    "plt.title('Probability Density Functions of Proposal Distributions')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('p(x)')\n",
    "plt.show()\n",
    "\n",
    "# Plot the weight functions of all three proposal distributions\n",
    "plt.plot(x, w1, label='t-distribution with 3 degrees of freedom')\n",
    "plt.plot(x, w2, label='t-distribution with 1 degree of freedom')\n",
    "plt.plot(x, w3, label='standard Normal distribution')\n",
    "plt.legend()\n",
    "plt.title('Weight Functions of Proposal Distributions')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('w(x)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to be integrated\n",
    "f = lambda x: np.abs(x)\n",
    "log_p_bar = lambda x: -2 * np.log(1 + x**2/3)\n",
    "\n",
    "def importance_sampling(q, log_w, N):\n",
    "    x = q.rvs(N)\n",
    "    w = np.exp(log_w(x))\n",
    "    w_norm = w / np.sum(w)\n",
    "    I = np.sum(w_norm * f(x))\n",
    "    log_Z = np.log(np.sum(w)) - np.log(N)\n",
    "    ess = (np.sum(w_norm)*2) / np.sum(w_norm*2)\n",
    "    return I, log_Z, ess\n",
    "\n",
    "# Proposal distribution 1: t-distribution with 3 degrees of freedom\n",
    "q1 = t(df=3)\n",
    "log_q1 = lambda x: t.logpdf(x, df=3)\n",
    "log_w1 = lambda x: log_p_bar(x) - log_q1(x)\n",
    "I1, log_Z1, ess1 = importance_sampling(q1, log_w1, N=10000)\n",
    "\n",
    "# Proposal distribution 2: t-distribution with 1 degree of freedom\n",
    "q2 = t(df=1)\n",
    "log_q2 = lambda x: t.logpdf(x, df=1)\n",
    "log_w2 = lambda x: log_p_bar(x) - log_q2(x)\n",
    "I2, log_Z2, ess2 = importance_sampling(q2, log_w2, N=10000)\n",
    "\n",
    "# Proposal distribution 3: standard Normal distribution\n",
    "q3 = norm()\n",
    "log_q3 = lambda x: norm.logpdf(x)\n",
    "log_w3 = lambda x: log_p_bar(x) - log_q3(x)\n",
    "I3, log_Z3, ess3 = importance_sampling(q3, log_w3, N=10000)\n",
    "\n",
    "print(\"Proposal distribution 1: t-distribution with 3 degrees of freedom\")\n",
    "print(\"I = \", I1)\n",
    "print(\"log Z = \", log_Z1)\n",
    "print(\"Effective sample size = \", ess1)\n",
    "print()\n",
    "print(\"Proposal distribution 2: t-distribution with 1 degree of freedom\")\n",
    "print(\"I = \", I2)\n",
    "print(\"log Z = \", log_Z2)\n",
    "print(\"Effective sample size = \", ess2)\n",
    "print()\n",
    "print(\"Proposal distribution 3: standard Normal distribution\")\n",
    "print(\"I = \", I3)\n",
    "print(\"log Z = \", log_Z3)\n",
    "print(\"Effective sample size = \", ess3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The effective sample size (ESS) refers to the number of independent samples from the importance sampling distribution that are equivalent to the sample's size. A higher ESS value indicates a more efficient estimator since it reduces the variance of the estimator.\n",
    "\n",
    "Based on your research, the ESS for the first proposal distribution (a t-distribution with three degrees of freedom) is the highest possible value of 10,000, making it the most effective. The ESS for the second proposal distribution (a t-distribution with one degree of freedom) is lower at 8,642.80, while the ESS for the third proposal distribution (a typical normal distribution) is even lower at 8,132.26.\n",
    "\n",
    "Therefore, it can be concluded that the first proposal distribution is the most effective, while the third proposal distribution is the least effective. The second proposal distribution falls in the middle. The reason for the difference in ESS values is that the first proposal distribution is closer to the target distribution, resulting in more suggested samples with higher weights, leading to a more effective estimator."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SimulationBasedModels",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "860b0e55b53644b489f0c3c605d40abb1c10eea6729d2ddd193b64b9d40b4fc1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
